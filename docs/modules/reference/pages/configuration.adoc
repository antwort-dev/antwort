= Configuration Guide
:navtitle: Configuration Guide

Antwort uses a single YAML configuration file with layered overrides.
This page walks through each configuration section with annotated examples and explains common patterns for development and production deployments.

== Configuration Loading

Configuration is loaded in the following order, where later layers override earlier ones:

. **Built-in defaults** (compiled into the binary)
. **YAML config file** (discovered or explicitly specified)
. **Environment variable overrides** (`ANTWORT_*` prefix)
. **File reference resolution** (`_file` suffix fields read secrets from disk)
. **Validation** (required fields and valid value checks)

=== Config File Discovery

The gateway discovers the config file using this priority:

. `--config` command-line flag
. `ANTWORT_CONFIG` environment variable
. `./config.yaml` in the working directory
. `/etc/antwort/config.yaml`

If no config file is found, the gateway starts with built-in defaults and environment variable overrides.

=== The `_file` Suffix Convention

Several fields support a `_file` variant for loading secrets from files rather than embedding them in the config.
This is the recommended approach for Kubernetes deployments where secrets are mounted as files.

When a `_file` field is set and its corresponding value field is empty, the gateway reads the file, trims whitespace, and populates the value field.
For example, setting `api_key_file: /run/secrets/backend-key` reads the file and assigns its content to `api_key`.

Fields that support the `_file` convention:

* `engine.api_key_file` populates `engine.api_key`
* `storage.postgres.dsn_file` populates `storage.postgres.dsn`
* `auth.api_keys[].key_file` populates `auth.api_keys[].key`
* `mcp.servers[].auth.client_id_file` populates `mcp.servers[].auth.client_id`
* `mcp.servers[].auth.client_secret_file` populates `mcp.servers[].auth.client_secret`

== Server

The `server` section controls the HTTP listener and timeouts.

[source,yaml]
----
server:
  port: 8080            # <1>
  read_timeout: 30s     # <2>
  write_timeout: 120s   # <3>
----
<1> TCP port the gateway listens on.
<2> Maximum time to read the full request, including headers and body.
<3> Maximum time to write a response. Set this high enough to accommodate streaming responses and long inference calls.

For streaming deployments, we recommend keeping `write_timeout` at 120 seconds or higher.
If your inference backend produces long completions, increase this value accordingly.

== Engine

The `engine` section configures the inference backend and agentic loop behavior.

[source,yaml]
----
engine:
  provider: vllm              # <1>
  backend_url: http://vllm:8000  # <2>
  api_key: ""                 # <3>
  # api_key_file: /run/secrets/backend-api-key  # <4>
  default_model: ""           # <5>
  max_turns: 10               # <6>
----
<1> Provider type. Supported values: `vllm` (vLLM or any OpenAI-compatible backend), `litellm` (LiteLLM proxy), `vllm-responses` (native Responses API passthrough).
<2> Base URL of the backend Chat Completions endpoint. This field is **required**.
<3> API key for authenticating with the backend. Leave empty if the backend does not require authentication.
<4> Alternative: read the API key from a file (recommended for Kubernetes Secrets).
<5> Default model name used when the request omits the `model` field. When empty, clients must specify a model in every request.
<6> Maximum number of agentic loop turns before the engine returns an incomplete response. Prevents runaway tool-calling loops.

.Common engine configurations
[cols="1,3"]
|===
| Scenario | Configuration

| Local vLLM
| `provider: vllm`, `backend_url: http://localhost:8000`

| LiteLLM proxy
| `provider: litellm`, `backend_url: http://litellm:4000`, `api_key: sk-litellm-key`

| Responses API passthrough
| `provider: vllm-responses`, `backend_url: https://api.openai.com`
|===

== Storage

The `storage` section controls how the gateway persists response state.

[source,yaml]
----
storage:
  type: memory         # <1>
  max_size: 10000      # <2>
  postgres:            # <3>
    dsn: ""            # <4>
    # dsn_file: /run/secrets/postgres-dsn  # <5>
    max_conns: 25      # <6>
    migrate_on_start: false  # <7>
----
<1> Storage backend type. `memory` for an in-memory store (default), `postgres` for PostgreSQL.
<2> Maximum number of responses to keep in the memory store. Only applies when `type` is `memory`.
<3> PostgreSQL-specific settings. Only used when `type` is `postgres`.
<4> PostgreSQL connection string (DSN). **Required** when using PostgreSQL (or use `dsn_file`).
<5> Alternative: read the DSN from a file.
<6> Maximum number of connections in the PostgreSQL connection pool.
<7> When `true`, the gateway runs database migrations automatically on startup.

.Memory vs. PostgreSQL
[cols="1,1,1"]
|===
| Feature | Memory | PostgreSQL

| Persistence
| No (data lost on restart)
| Yes

| Horizontal scaling
| No (per-instance data)
| Yes (shared state)

| Setup
| None
| Requires PostgreSQL 14+
|===

== Auth

The `auth` section configures client authentication.

[source,yaml]
----
auth:
  type: none            # <1>
  api_keys:             # <2>
    - key: sk-my-api-key        # <3>
      # key_file: /run/secrets/api-key-alice  # <4>
      subject: alice            # <5>
      tenant_id: org-1          # <6>
      service_tier: standard    # <7>
  jwt:                  # <8>
    issuer: https://auth.example.com      # <9>
    audience: antwort                     # <10>
    jwks_url: https://auth.example.com/.well-known/jwks.json  # <11>
    user_claim: sub             # <12>
    tenant_claim: tenant_id     # <13>
    scopes_claim: scope         # <14>
----
<1> Authentication type. `none` disables authentication (development only). `apikey` enables Bearer token validation against configured keys. `jwt` enables JWT/OIDC validation. `chain` tries API key first, then JWT.
<2> List of API key entries. Only used when `type` is `apikey` or `chain`.
<3> The API key value. Clients send this as `Authorization: Bearer sk-my-api-key`.
<4> Alternative: read the key from a file.
<5> Subject identifier for this key, used in logging and audit.
<6> Tenant identifier. Enables multi-tenant data isolation when using storage.
<7> Service tier label, echoed in responses.
<8> JWT/OIDC settings. Only used when `type` is `jwt` or `chain`.
<9> Expected `iss` claim in the JWT.
<10> Expected `aud` claim in the JWT.
<11> URL to fetch the JSON Web Key Set for signature verification. **Required** when using JWT.
<12> JWT claim to use as the subject identifier. Defaults to `sub`.
<13> JWT claim to use as the tenant identifier. Defaults to `tenant_id`.
<14> JWT claim to use for authorization scopes. Defaults to `scope`.

The health (`/healthz`), readiness (`/readyz`), and metrics (`/metrics`) endpoints bypass authentication regardless of the configured `auth.type`.

== MCP

The `mcp` section configures connections to external MCP (Model Context Protocol) servers for tool calling.

[source,yaml]
----
mcp:
  servers:                        # <1>
    - name: my-tools              # <2>
      transport: streamable-http  # <3>
      url: http://localhost:3000/mcp  # <4>
      headers:                    # <5>
        X-Custom-Header: value
      auth:                       # <6>
        type: static              # <7>
    - name: secured-tools
      transport: sse
      url: http://secure-mcp:3000/sse
      auth:
        type: oauth_client_credentials  # <8>
        token_url: https://auth.example.com/token  # <9>
        client_id: my-client              # <10>
        client_secret_file: /run/secrets/mcp-secret  # <11>
        scopes:                           # <12>
          - tools:read
----
<1> List of MCP server connections.
<2> Unique name for this server. Used in logging and tool routing.
<3> Transport protocol: `streamable-http` or `sse`.
<4> URL of the MCP server endpoint.
<5> Additional HTTP headers to send with every request.
<6> Authentication configuration for this MCP server.
<7> `static` uses the headers as-is (e.g., a pre-shared Bearer token in `headers`).
<8> `oauth_client_credentials` acquires tokens via the OAuth 2.0 client credentials flow.
<9> OAuth token endpoint URL.
<10> OAuth client ID (or use `client_id_file`).
<11> OAuth client secret loaded from a file.
<12> OAuth scopes to request.

== Providers

The `providers` section enables built-in function providers that the engine executes server-side.

[source,yaml]
----
providers:
  web_search:                  # <1>
    enabled: true
    settings:                  # <2>
      api_key: "..."
  file_search:
    enabled: true
    settings: {}
  code_interpreter:            # <3>
    enabled: true
    settings:
      sandbox_url: http://sandbox:8080
----
<1> Each key is a provider name (`web_search`, `file_search`, `code_interpreter`).
<2> Provider-specific settings passed as a key-value map.
<3> The `code_interpreter` provider requires a sandbox server URL.

== Observability

The `observability` section controls monitoring and instrumentation.

[source,yaml]
----
observability:
  metrics:
    enabled: true       # <1>
    path: /metrics      # <2>
----
<1> Enable or disable the Prometheus metrics endpoint. Enabled by default.
<2> HTTP path for the metrics endpoint.

When enabled, the gateway exposes Prometheus metrics at the configured path, including request counts, latencies, streaming connection gauges, and OpenTelemetry GenAI semantic convention metrics.

== Logging

The `logging` section controls log verbosity and debug categories.

[source,yaml]
----
logging:
  level: INFO           # <1>
  debug: ""             # <2>
----
<1> Log level: `ERROR`, `WARN`, `INFO`, `DEBUG`, or `TRACE`. Defaults to `INFO`.
<2> Comma-separated list of debug categories to enable (e.g., `providers,engine`). Empty string disables category-specific debug output.

== Complete Example

The following shows a production-ready configuration using PostgreSQL storage, API key authentication, and an MCP tool server:

[source,yaml]
----
server:
  port: 8080
  write_timeout: 180s

engine:
  provider: vllm
  backend_url: http://vllm:8000
  api_key_file: /run/secrets/backend-api-key
  default_model: meta-llama/Llama-3.1-70B-Instruct
  max_turns: 15

storage:
  type: postgres
  postgres:
    dsn_file: /run/secrets/postgres-dsn
    max_conns: 50
    migrate_on_start: true

auth:
  type: apikey
  api_keys:
    - key_file: /run/secrets/api-key-alice
      subject: alice
      tenant_id: team-a
      service_tier: standard
    - key_file: /run/secrets/api-key-bob
      subject: bob
      tenant_id: team-b
      service_tier: premium

mcp:
  servers:
    - name: internal-tools
      transport: streamable-http
      url: http://mcp-server:3000/mcp

observability:
  metrics:
    enabled: true

logging:
  level: INFO
----
